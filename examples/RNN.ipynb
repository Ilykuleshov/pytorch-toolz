{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_toolz.functools import Parallel, Reduce, Sequential\n",
    "from pytorch_toolz.operator import Apply\n",
    "from pytorch_toolz.itertools import Accumulate\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_swap_args = Sequential(Apply(lambda *args: reversed(args)), nn.LSTMCell(8, 8), unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Accumulate(\n",
    "    lstm_swap_args,\n",
    "    initial=(torch.zeros(8),torch.zeros(8))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       " (tensor([-0.1169, -0.1231, -0.0435,  0.0198,  0.0099, -0.0187,  0.1105, -0.1274],\n",
       "         grad_fn=<SqueezeBackward1>),\n",
       "  tensor([-0.2014, -0.2099, -0.0677,  0.0544,  0.0229, -0.0424,  0.1618, -0.3059],\n",
       "         grad_fn=<SqueezeBackward1>)),\n",
       " (tensor([-0.2002, -0.2166, -0.2359, -0.1195,  0.0066, -0.0417,  0.2290, -0.0610],\n",
       "         grad_fn=<SqueezeBackward1>),\n",
       "  tensor([-0.5265, -0.3692, -0.4439, -0.2452,  0.0159, -0.1192,  0.3718, -0.2119],\n",
       "         grad_fn=<SqueezeBackward1>)),\n",
       " (tensor([-0.1117, -0.0792, -0.0294, -0.0389, -0.0587, -0.0109,  0.1151, -0.0082],\n",
       "         grad_fn=<SqueezeBackward1>),\n",
       "  tensor([-0.2048, -0.1397, -0.0470, -0.0773, -0.1346, -0.0393,  0.2663, -0.0110],\n",
       "         grad_fn=<SqueezeBackward1>)),\n",
       " (tensor([-0.0747, -0.1049, -0.2728, -0.0056, -0.2044, -0.0609, -0.0762, -0.0974],\n",
       "         grad_fn=<SqueezeBackward1>),\n",
       "  tensor([-0.1311, -0.1526, -0.4196, -0.0213, -0.4556, -0.2212, -0.1507, -0.2191],\n",
       "         grad_fn=<SqueezeBackward1>)),\n",
       " (tensor([-0.0571, -0.1689, -0.0234, -0.0487,  0.0649, -0.0219,  0.1568, -0.0156],\n",
       "         grad_fn=<SqueezeBackward1>),\n",
       "  tensor([-0.1349, -0.4023, -0.0592, -0.0845,  0.1375, -0.0398,  0.2185, -0.0359],\n",
       "         grad_fn=<SqueezeBackward1>)),\n",
       " (tensor([-0.2478, -0.3480, -0.0795, -0.1377,  0.2399, -0.1051,  0.1543, -0.0598],\n",
       "         grad_fn=<SqueezeBackward1>),\n",
       "  tensor([-0.4826, -0.5707, -0.1842, -0.2427,  0.4265, -0.2191,  0.2627, -0.1096],\n",
       "         grad_fn=<SqueezeBackward1>)),\n",
       " (tensor([-0.2695, -0.1459,  0.0792,  0.0183,  0.1077, -0.0037,  0.3350, -0.0458],\n",
       "         grad_fn=<SqueezeBackward1>),\n",
       "  tensor([-0.5426, -0.3280,  0.1458,  0.0328,  0.2878, -0.0074,  0.5037, -0.0695],\n",
       "         grad_fn=<SqueezeBackward1>)),\n",
       " (tensor([-0.2814, -0.1228,  0.2228,  0.0224,  0.1046,  0.2125,  0.4215, -0.0726],\n",
       "         grad_fn=<SqueezeBackward1>),\n",
       "  tensor([-0.8321, -0.4715,  0.5940,  0.0449,  0.3788,  0.2802,  0.5295, -0.1317],\n",
       "         grad_fn=<SqueezeBackward1>)),\n",
       " (tensor([-0.3984, -0.3564,  0.1977, -0.0019,  0.3024,  0.0190,  0.1941, -0.1733],\n",
       "         grad_fn=<SqueezeBackward1>),\n",
       "  tensor([-0.7760, -0.6502,  0.4221, -0.0036,  0.6111,  0.0366,  0.2825, -0.3267],\n",
       "         grad_fn=<SqueezeBackward1>)),\n",
       " (tensor([-0.1496, -0.2581,  0.2053, -0.0111, -0.1390, -0.0153,  0.1162, -0.1960],\n",
       "         grad_fn=<SqueezeBackward1>),\n",
       "  tensor([-0.2743, -0.4662,  0.4562, -0.0242, -0.3116, -0.0377,  0.2977, -0.2444],\n",
       "         grad_fn=<SqueezeBackward1>)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = torch.randn(10, 8)\n",
    "\n",
    "rnn(seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
